// Module included in the following assemblies:
//
// * documentation/doc-Migration_Toolkit_for_Virtualization/master.adoc

:_content-type: PROCEDURE
[id="new-migrating-virtual-machines-cli_{context}"]

ifdef::vmware[]
= Migrating a VMware vSphere source provider

You can migrate a VMware vSphere source provider using the CLI.

endif::[]
ifdef::rhv[]
= Migrating a {rhv-full} source provider

You can migrate a {rhv-full} ({rhv-short}) source provider using the CLI.

.Prerequisites

If you are migrating a virtual machine with a direct LUN disk, ensure that the nodes in the {virt} destination cluster that the VM is expected to run on can access the backend storage.

include::snip-migrating-luns.adoc[]

endif::[]
ifdef::ova[]
= Migrating an Open Virtual Appliance (OVA) source provider

You can migrate Open Virtual Appliance (OVA) files that were created by VMware vSphere as a source provider using the CLI.

include::snippet_ova_tech_preview.adoc[]
endif::[]
ifdef::ostack[]
= Migrating an {osp} source provider

You can migrate an {osp} source provider using the CLI.

[NOTE]
====
Migration using {osp} source providers only supports VMs that use only Cinder volumes.
====
endif::[]
ifdef::cnv[]
= Migrating a Red Hat {virt} source provider

You can use a Red Hat {virt} provider as both a source provider and destination provider.

Specifically, the host cluster that is automatically added as a {virt} provider can be used as both a source provider and a destination provider.

You can use the CLI to migrate VMs from the cluster that {project-short} is deployed on to another cluster, or from a remote cluster to the cluster that {project-short} is deployed on.
endif::[]

.Procedure
. Create a `Secret` manifest for the source provider credentials:
+
ifdef::vmware[]
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: v1
kind: Secret
metadata:
  name: <secret>
  namespace: <namespace>
  ownerReferences: <1>
    - apiVersion: forklift.konveyor.io/v1beta1
      kind: Provider
      name: <provider_name>
      uid: <provider_uid>
  labels:
    createdForProviderType: vsphere
    createdForResourceType: providers
type: Opaque
stringData:
  user: <user> <2>
  password: <password> <3>
  insecureSkipVerify: <true/false> <4>
  cacert: | <5>
    <ca_certificate>
  url: <api_end_point> <6>
EOF
----
<1> The `ownerReferences` section is optional.
<2> Specify the vCenter user.
<3> Specify the user password.
<4> Specify `<true>` to skip certificate verification, specify `false` to verify the certificate. Defaults to `false` if not specified. Skipping certificate verification proceeds with an insecure migration and then the certificate is not required. Insecure migration means that the transferred data is sent over an insecure connection and potentially sensitive data could be exposed.
<5> Enter the CA certificate for the server that serves the SDK, either vCenter or ESXi, depending on the configuration of the provider, unless the CA certificate was replaced by a third-party certificate, in which case, enter the {manager} Apache CA certificate. You can retrieve the {manager} CA certificate at https://<engine_host>/ovirt-engine/services/pki-resource?resource=ca-certificate&format=X509-PEM-CA.
<6> Specify the API end point URL, for example, `https://<vCenter_host>/sdk`.
endif::[]
ifdef::rhv[]
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: v1
kind: Secret
metadata:
  name: <secret>
  namespace: <namespace>
  ownerReferences: <1>
    - apiVersion: forklift.konveyor.io/v1beta1
      kind: Provider
      name: <provider_name>
      uid: <provider_uid>
  labels:
    createdForProviderType: ovirt
    createdForResourceType: providers
type: Opaque
stringData:
  user: <user> <2>
  password: <password> <3>
  insecureSkipVerify: <true/false> <4>
  cacert: | <5>
    <ca_certificate>
  url: <api_end_point> <6>
EOF
----
<1> The `ownerReferences` section is optional.
<2> Specify the {rhv-short} {manager} user.
<3> Specify the user password.
<4> Specify `<true>` to skip certificate verification, specify `false` to verify the certificate. Defaults to `false` if not specified. Skipping certificate verification proceeds with an insecure migration and then the certificate is not required. Insecure migration means that the transferred data is sent over an insecure connection and potentially sensitive data could be exposed.
<5> Enter the CA certificate for the API server of the OpenShift cluster, unless it was replaced by a third-party certificate, in which case, enter the {manager} Apache CA certificate. You can retrieve the {manager} CA certificate at https://<engine_host>/ovirt-engine/services/pki-resource?resource=ca-certificate&format=X509-PEM-CA.
<6> Specify the API end point URL, for example, `https://<engine_host>/ovirt-engine/api`.
endif::[]
ifdef::ova[]
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: v1
kind: Secret
metadata:
  name: <secret>
  namespace: <namespace>
  ownerReferences: <1>
    - apiVersion: forklift.konveyor.io/v1beta1
      kind: Provider
      name: <provider_name>
      uid: <provider_uid>
  labels:
    createdForProviderType: ova
    createdForResourceType: providers
type: Opaque
stringData:
  url: <nfs_server:/nfs_path> <2>
EOF
----
<1> The `ownerReferences` section is optional.
<2> where: `nfs_server` is an IP or hostname of the server where the share was created and `nfs_path` is the path on the server where the OVA files are stored.
endif::[]
ifdef::ostack[]
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: v1
kind: Secret
metadata:
  name: <secret>
  namespace: <namespace>
  ownerReferences: <1>
    - apiVersion: forklift.konveyor.io/v1beta1
      kind: Provider
      name: <provider_name>
      uid: <provider_uid>
  labels:
    createdForProviderType: openstack
    createdForResourceType: providers
type: Opaque
stringData:
  user: <user> <2>
  password: <password> <3>
  insecureSkipVerify: <true/false> <4>
  domainName: <domain_name>
  projectName: <project_name>
  regionName: <region name> <5>
  cacert: | <6>
    <ca_certificate>
  url: <api_end_point> <7>
EOF
----
<1> The `ownerReferences` section is optional.
<2> Specify the {osp} user.
<3> Specify the user password.
<4> Specify `<true>` to skip certificate verification, specify `false` to verify the certificate. Defaults to `false` if not specified. Skipping certificate verification proceeds with an insecure migration and then the certificate is not required. Insecure migration means that the transferred data is sent over an insecure connection and potentially sensitive data could be exposed.
<5> Specify the name of the {osp} region.
<6> Enter the CA certificate for connecting to the source environment. The certificate is not used when `insecureSkipVerify` is set to `<true>`. Note that if you set `insecureSkipVerify` to `false` and you do not set  `cacert`, {project-short} attempts to use the system CA.
<7> Specify the API end point URL, for example, `https://<identity_service>/v3`.
endif::[]

ifdef::cnv[]
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: v1
kind: Secret
metadata:
  name: <secret>
  namespace: <namespace>
  ownerReferences: <1>
    - apiVersion: forklift.konveyor.io/v1beta1
      kind: Provider
      name: <provider_name>
      uid: <provider_uid>
  labels:
    createdForProviderType: openshift
    createdForResourceType: providers
type: Opaque
stringData:
  user: <user> <2>
  password: <password> <3>
  insecureSkipVerify: <true/false> <4>
  cacert: | <5>
    <ca_certificate>
  url: <api_end_point> <6>
EOF
----
<1> The `ownerReferences` section is optional.
<2> Specify the {virt} user.
<3> Specify the user password.
<4> Specify `<true>` to skip certificate verification, specify `false` to verify the certificate. Defaults to `false` if not specified. Skipping certificate verification proceeds with an insecure migration and then the certificate is not required. Insecure migration means that the transferred data is sent over an insecure connection and potentially sensitive data could be exposed.
<5> Enter the {manager} CA certificate unless it was replaced by a third-party certificate, in which case, enter the {manager} Apache CA certificate. You can retrieve the {manager} CA certificate at https://<engine_host>/ovirt-engine/services/pki-resource?resource=ca-certificate&format=X509-PEM-CA.
<6> Specify the URL of the end point of the API server.
endif::[]

[start=2]
. Create a `Provider` manifest for the source provider:
+
ifdef::vmware[]
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: Provider
metadata:
  name: <source_provider>
  namespace: <namespace>
spec:
  type: vsphere
  url: <api_end_point> <1>
  settings:
    vddkInitImage: <registry_route_or_server_path>/vddk:<tag> <2>
    sdkEndpoint: <3>
  secret:
    name: <secret> <4>
    namespace: <namespace>
EOF
----
<1> Specify the API end point URL, for example, `https://<vCenter_host>/sdk`.
<2> Optional, but it is strongly recommended to accelerate migrations. Specify the VDDK image you created.
<3> Options: `vcenter` or `esxi`.
<4> Specify the name of the provider `Secret` CR.
endif::[]

ifdef::rhv[]
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: Provider
metadata:
  name: <source_provider>
  namespace: <namespace>
spec:
  type: ovirt
  url: <api_end_point> <1>
  secret:
    name: <secret> <2>
    namespace: <namespace>
EOF
----
<1> Specify the API end point URL, for example, `https://<engine_host>/ovirt-engine/api`.
<2> Specify the name of provider `Secret` CR.
endif::[]

ifdef::ova[]
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: Provider
metadata:
  name: <source_provider>
  namespace: <namespace>
spec:
  type: ova
  url:  <nfs_server:/nfs_path> <1>
  secret:
    name: <secret> <2>
    namespace: <namespace>
EOF
----
<1>  where: `nfs_server` is an IP or hostname of the server where the share was created and `nfs_path` is the path on the server where the OVA files are stored.
<2> Specify the name of provider `Secret` CR.
endif::[]

ifdef::ostack[]
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: Provider
metadata:
  name: <source_provider>
  namespace: <namespace>
spec:
  type: openstack
  url: <api_end_point> <1>
  secret:
    name: <secret> <2>
    namespace: <namespace>
EOF
----
<1> Specify the API end point URL, for example, `https://<identity_service>/v3`.
<2> Specify the name of provider `Secret` CR.
endif::[]

ifdef::cnv[]
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: Provider
metadata:
  name: <source_provider>
  namespace: <namespace>
spec:
  type: openshift
  url: <api_end_point> <1>
  secret:
    name: <secret> <2>
    namespace: <namespace>
EOF
----
<1> Specify the URL of the end point of the API server.
<2> Specify the name of provider `Secret` CR.
endif::[]

ifdef::vmware[]
[start=3]
. Create a `Host` manifest:
+
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: Host
metadata:
  name: <vmware_host>
  namespace: <namespace>
spec:
  provider:
    namespace: <namespace>
    name: <source_provider> <1>
  id: <source_host_mor> <2>
  ipAddress: <source_network_ip> <3>
EOF
----
<1> Specify the name of the VMware `Provider` CR.
<2> Specify the managed object reference (MOR) of the VMware host.
<3> Specify the IP address of the VMware migration network.

[start=4]
. Create a `NetworkMap` manifest to map the source and destination networks:
+
[source,yaml,subs="attributes+"]
----
$  cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: NetworkMap
metadata:
  name: <network_map>
  namespace: <namespace>
spec:
  map:
    - destination:
        name: <network_name>
        type: pod <1>
      source:
        id: <source_network_id> <2>
        name: <source_network_name>
    - destination:
        name: <network_attachment_definition> <3>
        namespace: <network_attachment_definition_namespace> <4>
        type: multus
      source:
        name: <network_attachment_definition> <5>
        namespace: <network_attachment_definition_namespace> <6>
  provider:
    source:
      name: <source_provider>
      namespace: <namespace>
    destination:
      name: <destination_provider>
      namespace: <namespace>
EOF
----
<1> Allowed values are `pod` and `multus`.
<2> You can use either the `id` _or_ the `name` parameter to specify the source network. For `id`, specify the VMware network MOR.
<3> Specify a network attachment definition for each additional {virt} network.
<4> Required only when `type` is `multus`. Specify the namespace of the {virt} network attachment definition.
<5> Specify a network attachment definition for each additional {virt} network.
<6> Required only when `type` is `multus`. Here, `namespace` can either be specified using the namespace property or with a name built as follows: `<network_namespace>/<network_name>`.
endif::[]

ifdef::rhv[]
[start=3]
. Create a `NetworkMap` manifest to map the source and destination networks:
+
[source,yaml,subs="attributes+"]
----
$  cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: NetworkMap
metadata:
  name: <network_map>
  namespace: <namespace>
spec:
  map:
    - destination:
        name: <network_name>
        type: pod <1>
      source:
        id: <source_network_id> <2>
        name: <source_network_name>
    - destination:
        name: <network_attachment_definition> <3>
        namespace: <network_attachment_definition_namespace> <4>
        type: multus
      source:
        name: <network_attachment_definition> <5>
        namespace: <network_attachment_definition_namespace> <6>
  provider:
    source:
      name: <source_provider>
      namespace: <namespace>
    destination:
      name: <destination_provider>
      namespace: <namespace>
EOF
----
<1> Allowed values are `pod` and `multus`.
<2> You can use either the `id` _or_ the `name` parameter to specify the source network. For `id`, specify the {rhv-short} network UUID.
<3> Specify a network attachment definition for each additional {virt} network.
<4> Required only when `type` is `multus`. Specify the namespace of the {virt} network attachment definition.
<5> Specify a network attachment definition for each additional {virt} network.
<6> Required only when `type` is `multus`. Here, `namespace` can either be specified using the namespace property or with a name built as follows: `<network_namespace>/<network_name>`.
endif::[]

ifdef::ova[]
[start=3]
. Create a `NetworkMap` manifest to map the source and destination networks:
+
[source,yaml,subs="attributes+"]
----
$  cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: NetworkMap
metadata:
  name: <network_map>
  namespace: <namespace>
spec:
  map:
    - destination:
        name: <network_name>
        type: pod <1>
      source:
        id: <source_network_id>
    - destination:
        name: <network_attachment_definition> <2>
        namespace: <network_attachment_definition_namespace> <3>
        type: multus
      source:
        name: <network_attachment_definition> <4>
        namespace: <network_attachment_definition_namespace> <5>
  provider:
    source:
      name: <source_provider>
      namespace: <namespace>
    destination:
      name: <destination_provider>
      namespace: <namespace>
EOF
----
<1> Allowed values are `pod` and `multus`.
<2> Specify a network attachment definition for each additional {virt} network.
<3> Required only when `type` is `multus`. Specify the namespace of the {virt} network attachment definition.
<4> Specify a network attachment definition for each additional {virt} network.
<5> Required only when `type` is `multus`. Here, `namespace` can either be specified using the namespace property or with a name built as follows: `<network_namespace>/<network_name>`.
endif::[]

ifdef::ostack[]
[start=3]
. Create a `NetworkMap` manifest to map the source and destination networks:
+
[source,yaml,subs="attributes+"]
----
$  cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: NetworkMap
metadata:
  name: <network_map>
  namespace: <namespace>
spec:
  map:
    - destination:
        name: <network_name>
        type: pod <1>
      source:
        id: <source_network_id> <2>
        name: <source_network_name>
    - destination:
        name: <network_attachment_definition> <3>
        namespace: <network_attachment_definition_namespace> <4>
        type: multus
      source:
        name: <network_attachment_definition> <5>
        namespace: <network_attachment_definition_namespace> <6>
  provider:
    source:
      name: <source_provider>
      namespace: <namespace>
    destination:
      name: <destination_provider>
      namespace: <namespace>
EOF
----
<1> Allowed values are `pod` and `multus`.
<2> You can use either the `id` _or_ the `name` parameter to specify the source network. For `id`, specify the {osp} network UUID.
<3> Specify a network attachment definition for each additional {virt} network.
<4> Required only when `type` is `multus`. Specify the namespace of the {virt} network attachment definition.
<5> Specify a network attachment definition for each additional {virt} network.
<6> Required only when `type` is `multus`. Here, `namespace` can either be specified using the namespace property or with a name built as follows: `<network_namespace>/<network_name>`.
endif::[]

ifdef::cnv[]
[start=3]
. Create a `NetworkMap` manifest to map the source and destination networks:
+
[source,yaml,subs="attributes+"]
----
$  cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: NetworkMap
metadata:
  name: <network_map>
  namespace: <namespace>
spec:
  map:
    - destination:
        name: <network_name>
        type: pod <1>
      source:
        id: <source_network_id> <2>
        name: <source_network_name>
    - destination:
        name: <network_attachment_definition> <3>
        namespace: <network_attachment_definition_namespace> <4>
        type: multus
      source:
        name: <network_attachment_definition> <5>
        namespace: <network_attachment_definition_namespace> <6>
        type: multus
  provider:
    source:
      name: <source_provider>
      namespace: <namespace>
    destination:
      name: <destination_provider>
      namespace: <namespace>
EOF
----
<1> Allowed values are `pod` and `multus`.
<2> You can use either the `id` _or_ the `name` parameter to specify the source network. For `id`, specify the virtual machine.
<3> Specify a network attachment definition for each additional {virt} network.
<4> Required only when `type` is `multus`. Specify the namespace of the {virt} network attachment definition.
<5> Specify a network attachment definition for each additional {virt} network.
<6> Required only when `type` is `multus`. Here, `namespace` can either be specified using the namespace property or with a name built as follows: `<network_namespace>/<network_name>`.
endif::[]

ifdef::vmware[]
[start=5]
. Create a `StorageMap` manifest to map source and destination storage:
+
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: StorageMap
metadata:
  name: <storage_map>
  namespace: <namespace>
spec:
  map:
    - destination:
        storageClass: <storage_class>
        accessMode: <access_mode> <1>
      source:
        id: <source_datastore> <2>
    - destination:
        storageClass: <storage_class>
        accessMode: <access_mode>
      source:
        id: <source_datastore>
  provider:
    source:
      name: <source_provider>
      namespace: <namespace>
    destination:
      name: <destination_provider>
      namespace: <namespace>
EOF
----
<1> Allowed values are `ReadWriteOnce` and `ReadWriteMany`.
<2> Specify the VMware data storage MOR. For example, `f2737930-b567-451a-9ceb-2887f6207009`.
endif::[]

ifdef::rhv[]
[start=4]
. Create a `StorageMap` manifest to map source and destination storage:
+
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: StorageMap
metadata:
  name: <storage_map>
  namespace: <namespace>
spec:
  map:
    - destination:
        storageClass: <storage_class>
        accessMode: <access_mode> <1>
      source:
        id: <source_datastore> <2>
    - destination:
        storageClass: <storage_class>
        accessMode: <access_mode>
      source:
        id: <source_datastore>
  provider:
    source:
      name: <source_provider>
      namespace: <namespace>
    destination:
      name: <destination_provider>
      namespace: <namespace>
EOF
----
<1> Allowed values are `ReadWriteOnce` and `ReadWriteMany`.
<2> Specify the {rhv-short} storage domain UUID. For example, `f2737930-b567-451a-9ceb-2887f6207009`.
endif::[]

ifdef::ova[]
[start=4]
. Create a `StorageMap` manifest to map source and destination storage:
+
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: StorageMap
metadata:
  name: <storage_map>
  namespace: <namespace>
spec:
  map:
    - destination:
        storageClass: <storage_class>
        accessMode: <access_mode> <1>
      source:
        name:  Dummy storage for source provider <provider_name> <2>
    - destination:
        storageClass: <storage_class>
        accessMode: <access_mode>
      source:
        name: <source_datastore>
  provider:
    source:
      name: <source_provider>
      namespace: <namespace>
    destination:
      name: <destination_provider>
      namespace: <namespace>
EOF
----
<1> Allowed values are `ReadWriteOnce` and `ReadWriteMany`.
<2> For OVA, the `StorageMap` can map only a single storage, which all the disks from the OVA are associated with, to a storage class at the destination. For this reason, the storage is referred to in the UI as "Dummy storage for source provider <provider_name>". In the YAML, write the phrase as it appears above, without the quotation marks and replacing <provider_name> with the actual name of the provider.
endif::[]

ifdef::ostack[]
[start=4]
. Create a `StorageMap` manifest to map source and destination storage:
+
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: StorageMap
metadata:
  name: <storage_map>
  namespace: <namespace>
spec:
  map:
    - destination:
        storageClass: <storage_class>
        accessMode: <access_mode> <1>
      source:
        id: <source_datastore> <2>
    - destination:
        storageClass: <storage_class>
        accessMode: <access_mode>
      source:
        id: <source_datastore>
  provider:
    source:
      name: <source_provider>
      namespace: <namespace>
    destination:
      name: <destination_provider>
      namespace: <namespace>
EOF
----
<1> Allowed values are `ReadWriteOnce` and `ReadWriteMany`.
<2> Specify the {osp} `volume_type` UUID. For example, `f2737930-b567-451a-9ceb-2887f6207009`.
endif::[]

ifdef::cnv[]
[start=4]
. Create a `StorageMap` manifest to map source and destination storage:
+
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: StorageMap
metadata:
  name: <storage_map>
  namespace: <namespace>
spec:
  map:
    - destination:
        storageClass: <storage_class>
        accessMode: <access_mode> <1>
      source:
        name: <source_class>
    - destination:
        storageClass: <storage_class>
        accessMode: <access_mode>
      source:
        name: <storage_class>
  provider:
    source:
      name: <source_provider>
      namespace: <namespace>
    destination:
      name: <destination_provider>
      namespace: <namespace>
EOF
----
<1> Allowed values are `ReadWriteOnce` and `ReadWriteMany`.
endif::[]
+
. Optional: Create a `Hook` manifest to run custom code on a VM during the phase specified in the `Plan` CR:
+
[source,yaml,subs="attributes+"]
----
$  cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: Hook
metadata:
  name: <hook>
  namespace: <namespace>
spec:
  image: quay.io/konveyor/hook-runner
  playbook: |
    LS0tCi0gbmFtZTogTWFpbgogIGhvc3RzOiBsb2NhbGhvc3QKICB0YXNrczoKICAtIG5hbWU6IExv
    YWQgUGxhbgogICAgaW5jbHVkZV92YXJzOgogICAgICBmaWxlOiAiL3RtcC9ob29rL3BsYW4ueW1s
    IgogICAgICBuYW1lOiBwbGFuCiAgLSBuYW1lOiBMb2FkIFdvcmtsb2FkCiAgICBpbmNsdWRlX3Zh
    cnM6CiAgICAgIGZpbGU6ICIvdG1wL2hvb2svd29ya2xvYWQueW1sIgogICAgICBuYW1lOiB3b3Jr
    bG9hZAoK
EOF
----
+
where:
+
`playbook` refers to an optional Base64-encoded Ansible playbook. If you specify a playbook, the `image` must be `hook-runner`.
+
[NOTE]
====
You can use the default `hook-runner` image or specify a custom image. If you specify a custom image, you do not have to specify a playbook.
====

ifdef::vmware[]
[start=7]
. Create a `Plan` manifest for the migration:
+
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: Plan
metadata:
  name: <plan> <1>
  namespace: <namespace>
spec:
  warm: false <2>
  provider:
    source:
      name: <source_provider>
      namespace: <namespace>
    destination:
      name: <destination_provider>
      namespace: <namespace>
  map: <3>
    network: <4>
      name: <network_map> <5>
      namespace: <namespace>
    storage: <6>
      name: <storage_map> <7>
      namespace: <namespace>
  targetNamespace: <target_namespace>
  vms: <8>
    - id: <source_vm> <9>
    - name: <source_vm>
      hooks: <10>
        - hook:
            namespace: <namespace>
            name: <hook> <11>
          step: <step> <12>
EOF
----
<1> Specify the name of the `Plan` CR.
<2> Specify whether the migration is warm - `true` - or cold - `false`. If you specify a warm migration without specifying a value for the `cutover` parameter in the `Migration` manifest, only the precopy stage will run.
<3> Specify only one network map and one storage map per plan.
<4> Specify a network mapping even if the VMs to be migrated are not assigned to a network. The mapping can be empty in this case.
<5> Specify the name of the `NetworkMap` CR.
<6> Specify a storage mapping even if the VMs to be migrated are not assigned with disk images. The mapping can be empty in this case.
<7> Specify the name of the `StorageMap` CR.
<8> You can use either the `id` _or_ the `name` parameter to specify the source VMs. +
<9> Specify the VMware VM MOR..
<10> Optional: You can specify up to two hooks for a VM. Each hook must run during a separate migration step.
<11> Specify the name of the `Hook` CR.
<12> Allowed values are `PreHook`, before the migration plan starts, or `PostHook`, after the migration is complete.
endif::[]

ifdef::rhv[]
[start=6]
. Create a `Plan` manifest for the migration:
+
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: Plan
metadata:
  name: <plan> <1>
  namespace: <namespace>
  preserveClusterCpuModel: true <2>
spec:
  warm: true <3>
  provider:
    source:
      name: <source_provider>
      namespace: <namespace>
    destination:
      name: <destination_provider>
      namespace: <namespace>
  map: <4>
    network: <5>
      name: <network_map> <6>
      namespace: <namespace>
    storage: <7>
      name: <storage_map> <8>
      namespace: <namespace>
  targetNamespace: <target_namespace>
  vms: <9>
    - id: <source_vm> <10>
    - name: <source_vm>
      hooks: <11>
        - hook:
            namespace: <namespace>
            name: <hook> <12>
          step: <step> <13>
EOF
----
<1> Specify the name of the `Plan` CR.
<2> Keeps stuff
<3> Specify whether the migration is warm or cold. If you specify a warm migration without specifying a value for the `cutover` parameter in the `Migration` manifest, only the precopy stage will run.
<4> Specify only one network map and one storage map per plan.
<5> Specify a network mapping even if the VMs to be migrated are not assigned to a network. The mapping can be empty in this case.
<6> Specify the name of the `NetworkMap` CR.
<7> Specify a storage mapping even if the VMs to be migrated are not assigned with disk images. The mapping can be empty in this case.
<8> Specify the name of the `StorageMap` CR.
<9> You can use either the `id` _or_ the `name` parameter to specify the source VMs.
<10> Specify the {rhv-short} VM UUID.
<11> Optional: You can specify up to two hooks for a VM. Each hook must run during a separate migration step.
<12> Specify the name of the `Hook` CR.
<13> Allowed values are `PreHook`, before the migration plan starts, or `PostHook`, after the migration is complete.
endif::[]

ifdef::ova[]
[start=6]
. Create a `Plan` manifest for the migration:
+
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: Plan
metadata:
  name: <plan> <1>
  namespace: <namespace>
spec:
  warm: false <2>
  provider:
    source:
      name: <source_provider>
      namespace: <namespace>
    destination:
      name: <destination_provider>
      namespace: <namespace>
  map: <3>
    network: <4>
      name: <network_map> <5>
      namespace: <namespace>
    storage: <6>
      name: <storage_map> <7>
      namespace: <namespace>
  targetNamespace: <target_namespace>
  vms: <8>
    - id: <source_vm> <9>
    - name: <source_vm>
      hooks: <10>
        - hook:
            namespace: <namespace>
            name: <hook> <11>
          step: <step> <12>
EOF
----
<1> Specify the name of the `Plan` CR.
<2> Specify whether the migration is warm - `true` - or cold - `false`. If you specify a warm migration without specifying a value for the `cutover` parameter in the `Migration` manifest, only the precopy stage will run.
<3> Specify only one network map and one storage map per plan.
<4> Specify a network mapping, even if the VMs to be migrated are not assigned to a network. The mapping can be empty in this case.
<5> Specify the name of the `NetworkMap` CR.
<6> Specify a storage mapping even if the VMs to be migrated are not assigned with disk images. The mapping can be empty in this case.
<7> Specify the name of the `StorageMap` CR.
<8> You can use either the `id` _or_ the `name` parameter to specify the source VMs.
<9> Specify the TBD.
<10> Optional: You can specify up to two hooks for a VM. Each hook must run during a separate migration step.
<11> Specify the name of the `Hook` CR.
<12> Allowed values are `PreHook`, before the migration plan starts, or `PostHook`, after the migration is complete.
endif::[]

ifdef::ostack[]
[start=6]
. Create a `Plan` manifest for the migration:
+
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: Plan
metadata:
  name: <plan> <1>
  namespace: <namespace>
spec:
  warm: false <2>
  provider:
    source:
      name: <source_provider>
      namespace: <namespace>
    destination:
      name: <destination_provider>
      namespace: <namespace>
  map: <3>
    network: <4>
      name: <network_map> <5>
      namespace: <namespace>
    storage: <6>
      name: <storage_map> <7>
      namespace: <namespace>
  targetNamespace: <target_namespace>
  vms: <8>
    - id: <source_vm> <9>
    - name: <source_vm>
      hooks: <10>
        - hook:
            namespace: <namespace>
            name: <hook> <11>
          step: <step> <12>
EOF
----
<1> Specify the name of the `Plan` CR.
<2> Specify whether the migration is warm - `true` - or cold - `false`. If you specify a warm migration without specifying a value for the `cutover` parameter in the `Migration` manifest, only the precopy stage will run.
<3> Specify only one network map and one storage map per plan.
<4> Specify a network mapping, even if the VMs to be migrated are not assigned to a network. The mapping can be empty in this case.
<5> Specify the name of the `NetworkMap` CR.
<6> Specify a storage mapping, even if the VMs to be migrated are not assigned with disk images. The mapping can be empty in this case.
<7> Specify the name of the `StorageMap` CR.
<8> You can use either the `id` _or_ the `name` parameter to specify the source VMs.
<9> Specify the {osp} VM UUID.
<10> Optional: You can specify up to two hooks for a VM. Each hook must run during a separate migration step.
<11> Specify the name of the `Hook` CR.
<12> Allowed values are `PreHook`, before the migration plan starts, or `PostHook`, after the migration is complete.
endif::[]

ifdef::cnv[]
[start=6]
. Create a `Plan` manifest for the migration:
+
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: Plan
metadata:
  name: <plan> <1>
  namespace: <namespace>
spec:
  warm: false <2>
  provider:
    source:
      name: <source_provider>
      namespace: <namespace>
    destination:
      name: <destination_provider>
      namespace: <namespace>
  map: <3>
    network: <4>
      name: <network_map> <5>
      namespace: <namespace>
    storage: <6>
      name: <storage_map> <7>
      namespace: <namespace>
  targetNamespace: <target_namespace>
  vms:
    - name: <source_vm>
      namespace: <namespace>
      hooks: <8>
        - hook:
            namespace: <namespace>
            name: <hook> <9>
          step: <step> <10>
EOF
----
<1> Specify the name of the `Plan` CR.
<2> Specify whether the migration is warm - `true` - or cold - `false`. If you specify a warm migration without specifying a value for the `cutover` parameter in the `Migration` manifest, only the precopy stage will run.
<3> Specify only one network map and one storage map per plan.
<4> Specify a network mapping, even if the VMs to be migrated are not assigned to a network. The mapping can be empty in this case.
<5> Specify the name of the `NetworkMap` CR.
<6> Specify a storage mapping, even if the VMs to be migrated are not assigned with disk images. The mapping can be empty in this case.
<7> Specify the name of the `StorageMap` CR.
<8> Optional: You can specify up to two hooks for a VM. Each hook must run during a separate migration step.
<9> Specify the name of the `Hook` CR.
<10> Allowed values are `PreHook`, before the migration plan starts, or `PostHook`, after the migration is complete.
endif::[]
+
. Create a `Migration` manifest to run the `Plan` CR:
+
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: Migration
metadata:
  name: <name_of_migration_cr>
  namespace: <namespace>
spec:
  plan:
    name: <name_of_plan_cr>
    namespace: <namespace>
  cutover: <optional_cutover_time>
EOF
----
+
[NOTE]
====
If you specify a cutover time, use the ISO 8601 format with the UTC time offset, for example, `2024-04-04T01:23:45.678+09:00`.
====


